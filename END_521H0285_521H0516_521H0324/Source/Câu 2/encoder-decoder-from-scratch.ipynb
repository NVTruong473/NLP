{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install evaluate rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:16:28.628819Z","iopub.execute_input":"2025-05-14T00:16:28.629072Z","iopub.status.idle":"2025-05-14T00:16:35.562003Z","shell.execute_reply.started":"2025-05-14T00:16:28.629052Z","shell.execute_reply":"2025-05-14T00:16:35.561047Z"},"id":"jmjYiwqakChL","outputId":"d5da813f-88ac-4af6-bb26-3456a63be6db","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e94cd5aefaed264496d0ca7129e6cb24d23eb0dfbbdcfcbb1c47ba98ca38d319\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: fsspec, rouge_score, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2025.3.0 rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nimport numpy as np\nimport math\nimport time\nimport evaluate\n\n# New imports for EDA & preprocessing\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport unicodedata\nfrom datasets import Dataset as HFDataset, DatasetDict, load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:16:35.563179Z","iopub.execute_input":"2025-05-14T00:16:35.563429Z","iopub.status.idle":"2025-05-14T00:17:02.399302Z","shell.execute_reply.started":"2025-05-14T00:16:35.563405Z","shell.execute_reply":"2025-05-14T00:17:02.398639Z"},"id":"qvt8fc5XkChM"},"outputs":[{"name":"stderr","text":"2025-05-14 00:16:46.145181: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747181806.356429      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747181806.410142      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:02.400686Z","iopub.execute_input":"2025-05-14T00:17:02.401236Z","iopub.status.idle":"2025-05-14T00:17:02.405788Z","shell.execute_reply.started":"2025-05-14T00:17:02.401217Z","shell.execute_reply":"2025-05-14T00:17:02.405102Z"},"id":"UspMJEx2kChM","outputId":"b4db3451-c36c-4d5d-ab2f-c0b27f2fdf5a"},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load metrics\nbleu = evaluate.load(\"bleu\")\nrouge = evaluate.load(\"rouge\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:02.406516Z","iopub.execute_input":"2025-05-14T00:17:02.407485Z","iopub.status.idle":"2025-05-14T00:17:04.631427Z","shell.execute_reply.started":"2025-05-14T00:17:02.407456Z","shell.execute_reply":"2025-05-14T00:17:04.630840Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"299b2153456149a0ac81e0977bfbbd6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c39368e7ca4d45afc641c75d643310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85e9a269582b4e5f8fced3b1561c7e02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e275670b53fd43d093966251d19134fb"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Data Preparation: load, EDA, preprocessing (10% sample)\ndataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-vi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:04.632119Z","iopub.execute_input":"2025-05-14T00:17:04.632361Z","iopub.status.idle":"2025-05-14T00:17:08.635120Z","shell.execute_reply.started":"2025-05-14T00:17:04.632341Z","shell.execute_reply":"2025-05-14T00:17:08.634352Z"},"id":"FVu6azpGkChN"},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce8f3e8c260e4d1ab044da64bdbe5665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/137k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94e47b64b2c645efbf62c502d6fe2308"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/59.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"591745a3bf234f48a8afe541d827f409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/138k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d8000909e5c490187e214970d9b83c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc34783e44764ea896b76b9ef72d2808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ccc013256de466abe1448e9c7cdefa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a34bd61eed41d28e8ea65ff35cf285"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Take a 10% slice across train/validation/test\nall_data = []\nfor split in [\"train\", \"validation\", \"test\"]:\n    all_data.extend(dataset[split])\ntotal_samples = int(len(all_data) * 0.10)\nsampled_data = all_data[:total_samples]\nprint(f\"Total samples: {len(sampled_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:08.635887Z","iopub.execute_input":"2025-05-14T00:17:08.636194Z","iopub.status.idle":"2025-05-14T00:17:36.323593Z","shell.execute_reply.started":"2025-05-14T00:17:08.636174Z","shell.execute_reply":"2025-05-14T00:17:36.322900Z"},"id":"VoXMc0bkkChN","outputId":"88dbf334-4ed8-4994-edf9-93a45dc672c6"},"outputs":[{"name":"stdout","text":"Total samples: 100400\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Build a pandas DataFrame for EDA\ndf = pd.DataFrame([\n    {\"en\": ex[\"translation\"][\"en\"], \"vi\": ex[\"translation\"][\"vi\"]}\n    for ex in sampled_data\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:36.324262Z","iopub.execute_input":"2025-05-14T00:17:36.324538Z","iopub.status.idle":"2025-05-14T00:17:36.436117Z","shell.execute_reply.started":"2025-05-14T00:17:36.324514Z","shell.execute_reply":"2025-05-14T00:17:36.435475Z"},"id":"zVkACDX0kChN"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Raw-length and null/duplicate checks\ndf[\"en_len\"] = df[\"en\"].str.len()\ndf[\"vi_len\"] = df[\"vi\"].str.len()\n\nprint(f\"English nulls: {df['en'].isnull().sum()}\")\nprint(f\"Vietnamese nulls: {df['vi'].isnull().sum()}\\n\")\n\nprint(f\"Duplicate English: {df.duplicated(subset=['en']).sum()}\")\nprint(f\"Duplicate Vietnamese: {df.duplicated(subset=['vi']).sum()}\")\nprint(f\"Duplicate pairs: {df.duplicated().sum()}\\n\")\n\nprint(f\"Very long English (>=200): {(df['en_len'] >= 200).sum()}\")\nprint(f\"Very long Vietnamese (>=200): {(df['vi_len'] >= 200).sum()}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:36.436881Z","iopub.execute_input":"2025-05-14T00:17:36.437126Z","iopub.status.idle":"2025-05-14T00:17:36.651796Z","shell.execute_reply.started":"2025-05-14T00:17:36.437108Z","shell.execute_reply":"2025-05-14T00:17:36.650787Z"},"id":"YxRTJfUzkChN","outputId":"9f7cd515-ac47-4ef1-be28-6a40180fdcb5"},"outputs":[{"name":"stdout","text":"English nulls: 0\nVietnamese nulls: 0\n\nDuplicate English: 11047\nDuplicate Vietnamese: 8255\nDuplicate pairs: 4088\n\nVery long English (>=200): 102\nVery long Vietnamese (>=200): 90\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Plot length distributions\nplt.figure(figsize=(10, 5))\nplt.hist(df[\"en_len\"], bins=50, alpha=0.7, label=\"English\")\nplt.hist(df[\"vi_len\"], bins=50, alpha=0.7, label=\"Vietnamese\")\nplt.xlabel(\"Text Length\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Text Length Distribution\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:36.655507Z","iopub.execute_input":"2025-05-14T00:17:36.655756Z","iopub.status.idle":"2025-05-14T00:17:37.045524Z","shell.execute_reply.started":"2025-05-14T00:17:36.655737Z","shell.execute_reply":"2025-05-14T00:17:37.044736Z"},"id":"foHDa3qbkChO","outputId":"3db842e9-5a79-4ab0-cac2-5446a3fc01ba"},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Character set sizes\nen_chars = set(\"\".join(df[\"en\"].tolist()))\nvi_chars = set(\"\".join(df[\"vi\"].tolist()))\nprint(f\"Unique English characters: {len(en_chars)}\")\nprint(f\"Unique Vietnamese characters: {len(vi_chars)}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:37.046442Z","iopub.execute_input":"2025-05-14T00:17:37.047071Z","iopub.status.idle":"2025-05-14T00:17:37.165430Z","shell.execute_reply.started":"2025-05-14T00:17:37.047041Z","shell.execute_reply":"2025-05-14T00:17:37.164613Z"},"id":"9vd7pQdkkChO","outputId":"1197a455-5173-4aa7-8b28-dd07ba4651ef"},"outputs":[{"name":"stdout","text":"Unique English characters: 213\nUnique Vietnamese characters: 460\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Preprocessing functions\ndef preprocess_text(text, lowercase=True):\n    # Remove extra whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Remove special chars but keep punctuation\n    text = re.sub(r\"[^\\w\\s.,!?-]\", \"\", text)\n    # Unicode normalization\n    text = unicodedata.normalize(\"NFC\", text)\n    if lowercase:\n        text = text.lower()\n    return text\n\ndef clean_dataset(df):\n    df = df.dropna(subset=[\"en_clean\", \"vi_clean\"])\n    df = df[(df[\"en_clean\"].str.len() > 0) & (df[\"vi_clean\"].str.len() > 0)]\n    df = df.drop_duplicates(subset=[\"en_clean\", \"vi_clean\"])\n    df = df[(df[\"en_clean_len\"] >= 3) & (df[\"en_clean_len\"] <= 200)]\n    df = df[(df[\"vi_clean_len\"] >= 3) & (df[\"vi_clean_len\"] <= 200)]\n    length_ratio = df[\"vi_clean_len\"] / df[\"en_clean_len\"]\n    df = df[(length_ratio >= 0.3) & (length_ratio <= 3.0)]\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:37.166413Z","iopub.execute_input":"2025-05-14T00:17:37.166805Z","iopub.status.idle":"2025-05-14T00:17:37.172829Z","shell.execute_reply.started":"2025-05-14T00:17:37.166775Z","shell.execute_reply":"2025-05-14T00:17:37.172173Z"},"id":"Hzp-ubOZkChO"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Apply preprocessing\nprint(\"Preprocessing data...\")\ndf[\"en_clean\"] = df[\"en\"].map(lambda x: preprocess_text(x, True))\ndf[\"vi_clean\"] = df[\"vi\"].map(lambda x: preprocess_text(x, True))\ndf[\"en_clean_len\"] = df[\"en_clean\"].str.len()\ndf[\"vi_clean_len\"] = df[\"vi_clean\"].str.len()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:37.173593Z","iopub.execute_input":"2025-05-14T00:17:37.173863Z","iopub.status.idle":"2025-05-14T00:17:38.269970Z","shell.execute_reply.started":"2025-05-14T00:17:37.173840Z","shell.execute_reply":"2025-05-14T00:17:38.269227Z"},"id":"3PJjuLtekChO","outputId":"f07daec7-dcc7-45d2-88d6-28996785d0d7"},"outputs":[{"name":"stdout","text":"Preprocessing data...\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Clean and report removals\nprint(\"Cleaning data...\")\ndf_clean = clean_dataset(df)\nremoved = len(df) - len(df_clean)\nprint(f\"Removed {removed} samples ({removed/len(df)*100:.1f}%)\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:38.270687Z","iopub.execute_input":"2025-05-14T00:17:38.270909Z","iopub.status.idle":"2025-05-14T00:17:38.546941Z","shell.execute_reply.started":"2025-05-14T00:17:38.270893Z","shell.execute_reply":"2025-05-14T00:17:38.546044Z"},"id":"alTFjsDekChO","outputId":"4815f3e6-c0bb-44d6-e717-41edba6306e6"},"outputs":[{"name":"stdout","text":"Cleaning data...\nRemoved 5759 samples (5.7%)\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#  Split into train/validation/test (80/10/10)\ntrain_df = df_clean.sample(frac=0.8, random_state=42)\ntemp_df  = df_clean.drop(train_df.index)\nval_df   = temp_df.sample(frac=0.5, random_state=42)\ntest_df  = temp_df.drop(val_df.index)\n\nprint(f\"Training set:   {len(train_df)} samples\")\nprint(f\"Validation set: {len(val_df)} samples\")\nprint(f\"Test set:       {len(test_df)} samples\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:38.547799Z","iopub.execute_input":"2025-05-14T00:17:38.548108Z","iopub.status.idle":"2025-05-14T00:17:38.825316Z","shell.execute_reply.started":"2025-05-14T00:17:38.548073Z","shell.execute_reply":"2025-05-14T00:17:38.824535Z"},"id":"xgTWSi2AkChO","outputId":"12c01890-e7e0-41cc-94eb-46692a8bb99a"},"outputs":[{"name":"stdout","text":"Training set:   75713 samples\nValidation set: 9464 samples\nTest set:       9464 samples\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Convert back to 🤗 Datasets\ntrain_dataset = HFDataset.from_pandas(train_df[[\"en_clean\",\"vi_clean\"]].reset_index(drop=True))\nval_dataset   = HFDataset.from_pandas(val_df[[\"en_clean\",\"vi_clean\"]].reset_index(drop=True))\ntest_dataset  = HFDataset.from_pandas(test_df[[\"en_clean\",\"vi_clean\"]].reset_index(drop=True))\n\nsampled_dataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:38.826150Z","iopub.execute_input":"2025-05-14T00:17:38.826407Z","iopub.status.idle":"2025-05-14T00:17:38.939283Z","shell.execute_reply.started":"2025-05-14T00:17:38.826387Z","shell.execute_reply":"2025-05-14T00:17:38.938511Z"},"id":"nP6sOZIPkChO"},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Prepare texts for tokenizer training\nen_texts = train_df[\"en_clean\"].tolist()\nvi_texts = train_df[\"vi_clean\"].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:38.940082Z","iopub.execute_input":"2025-05-14T00:17:38.940271Z","iopub.status.idle":"2025-05-14T00:17:38.949607Z","shell.execute_reply.started":"2025-05-14T00:17:38.940256Z","shell.execute_reply":"2025-05-14T00:17:38.949034Z"},"id":"qg4TMnkRkChP"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Improved BPE Tokenizer with better space handling\nclass BPETokenizer:\n    def __init__(self, vocab_size=8000):\n        self.vocab_size = vocab_size\n        self.special_tokens = {\n            \"<PAD>\": 0,\n            \"<UNK>\": 1,\n            \"<SOS>\": 2,\n            \"<EOS>\": 3,\n        }\n        self.vocab = {k: v for k, v in self.special_tokens.items()}\n        self.merges = {}\n\n    def train(self, texts, min_freq=2):\n        # Preprocess texts - add special marker before each space\n        processed_texts = []\n        for text in texts:\n            # Replace spaces with a special marker\n            processed_texts.append(text.lower().replace(' ', ' ▁'))\n\n        # Build vocabulary\n        words = []\n        for text in processed_texts:\n            words.extend(text.split())\n        word_freqs = Counter(words)\n\n        # Initialize character-level encoding\n        char_dict = {}\n        for word, freq in word_freqs.items():\n            if freq < min_freq:\n                continue\n            char_dict[word] = ' '.join(list(word))\n\n        # Add characters to vocab\n        char_set = set()\n        for chars in char_dict.values():\n            char_set.update(chars.split())\n\n        for char in sorted(char_set):\n            if char not in self.vocab:\n                self.vocab[char] = len(self.vocab)\n\n        # BPE algorithm: merge most frequent pairs\n        while len(self.vocab) < self.vocab_size:\n            pairs = Counter()\n            for word, split_word in char_dict.items():\n                symbols = split_word.split()\n                for i in range(len(symbols) - 1):\n                    pairs[(symbols[i], symbols[i+1])] += word_freqs[word]\n\n            if not pairs:\n                break\n\n            best_pair = max(pairs, key=pairs.get)\n            new_token = ''.join(best_pair)\n            self.vocab[new_token] = len(self.vocab)\n\n            # Update all words with the new merged token\n            for word in char_dict:\n                symbols = char_dict[word].split()\n                i = 0\n                new_symbols = []\n                while i < len(symbols):\n                    if i < len(symbols) - 1 and (symbols[i], symbols[i+1]) == best_pair:\n                        new_symbols.append(new_token)\n                        i += 2\n                    else:\n                        new_symbols.append(symbols[i])\n                        i += 1\n                char_dict[word] = ' '.join(new_symbols)\n\n            self.merges[best_pair] = new_token\n\n        # Create reverse mapping\n        self.id_to_token = {v: k for k, v in self.vocab.items()}\n\n    def encode(self, text):\n        # Add space marker\n        text = text.lower().replace(' ', ' ▁')\n\n        words = text.split()\n        result = [self.special_tokens[\"<SOS>\"]]\n\n        for word in words:\n            # Start with character-level\n            chars = ' '.join(list(word))\n            subwords = chars.split()\n\n            # Apply merges\n            while len(subwords) > 1:\n                pairs = [(subwords[i], subwords[i+1])\n                        for i in range(len(subwords) - 1)]\n                merged = False\n\n                for pair in pairs:\n                    if pair in self.merges:\n                        idx = subwords.index(pair[0])\n                        subwords = subwords[:idx] + [self.merges[pair]] + subwords[idx+2:]\n                        merged = True\n                        break\n\n                if not merged:\n                    break\n\n            # Add subwords to result\n            for subword in subwords:\n                result.append(self.vocab.get(subword, self.special_tokens[\"<UNK>\"]))\n\n        result.append(self.special_tokens[\"<EOS>\"])\n        return result\n\n    def decode(self, ids):\n        tokens = [self.id_to_token.get(id, \"<UNK>\") for id in ids\n                 if id not in [0, 2, 3]]  # Skip PAD, SOS, EOS\n\n        # Join and replace space markers with actual spaces\n        text = ''.join(tokens).replace('▁', ' ').strip()\n        return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:38.950334Z","iopub.execute_input":"2025-05-14T00:17:38.950520Z","iopub.status.idle":"2025-05-14T00:17:38.978594Z","shell.execute_reply.started":"2025-05-14T00:17:38.950506Z","shell.execute_reply":"2025-05-14T00:17:38.977916Z"},"id":"_E74AFnqkChP"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Train tokenizers\nsrc_tokenizer = BPETokenizer(vocab_size=10000)\ntrg_tokenizer = BPETokenizer(vocab_size=10000)\n\nprint(\"Training source tokenizer...\")\nsrc_tokenizer.train(en_texts)\nprint(\"Training target tokenizer...\")\ntrg_tokenizer.train(vi_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:17:38.979243Z","iopub.execute_input":"2025-05-14T00:17:38.979495Z","iopub.status.idle":"2025-05-14T00:27:44.243571Z","shell.execute_reply.started":"2025-05-14T00:17:38.979474Z","shell.execute_reply":"2025-05-14T00:27:44.242953Z"},"id":"_Svvvb_xkChP","outputId":"aad27cc9-f299-409a-c848-bd387686be7e"},"outputs":[{"name":"stdout","text":"Training source tokenizer...\nTraining target tokenizer...\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Dataset and dataloader\nclass TranslationDataset(Dataset):\n    def __init__(self, data, src_tokenizer, trg_tokenizer):\n        self.data = data\n        self.src_tokenizer = src_tokenizer\n        self.trg_tokenizer = trg_tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        src_text = item['en_clean']\n        trg_text = item['vi_clean']\n\n        src_tokens = self.src_tokenizer.encode(src_text)\n        trg_tokens = self.trg_tokenizer.encode(trg_text)\n\n        return {\n            'src': torch.tensor(src_tokens, dtype=torch.long),\n            'trg': torch.tensor(trg_tokens, dtype=torch.long),\n            'src_text': src_text,\n            'trg_text': trg_text\n        }\n\ndef collate_fn(batch):\n    src_batch = [item['src'] for item in batch]\n    trg_batch = [item['trg'] for item in batch]\n    src_text = [item['src_text'] for item in batch]\n    trg_text = [item['trg_text'] for item in batch]\n\n    src_lengths = [len(x) for x in src_batch]\n    trg_lengths = [len(x) for x in trg_batch]\n\n    max_src_len = max(src_lengths)\n    max_trg_len = max(trg_lengths)\n\n    # Pad sequences\n    src_padded = torch.zeros(len(batch), max_src_len, dtype=torch.long)\n    trg_padded = torch.zeros(len(batch), max_trg_len, dtype=torch.long)\n\n    for i, (src, trg) in enumerate(zip(src_batch, trg_batch)):\n        src_padded[i, :len(src)] = src\n        trg_padded[i, :len(trg)] = trg\n\n    return src_padded, trg_padded, src_text, trg_text\n\n# Create dataloaders\ntrain_dataset = TranslationDataset(sampled_dataset['train'], src_tokenizer, trg_tokenizer)\nvalid_dataset = TranslationDataset(sampled_dataset['validation'], src_tokenizer, trg_tokenizer)\ntest_dataset = TranslationDataset(sampled_dataset['test'], src_tokenizer, trg_tokenizer)\n\nBATCH_SIZE = 16\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:27:44.244330Z","iopub.execute_input":"2025-05-14T00:27:44.244567Z","iopub.status.idle":"2025-05-14T00:27:44.253706Z","shell.execute_reply.started":"2025-05-14T00:27:44.244543Z","shell.execute_reply":"2025-05-14T00:27:44.252978Z"},"id":"kW78kZqckChP"},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Transformer model\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_seq_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n                            -(math.log(10000.0) / d_model))\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:, :x.size(1)]\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab_size, trg_vocab_size, d_model=128, n_layers=2,\n                 n_heads=4, d_ff=256, dropout=0.1):\n        super().__init__()\n\n        # Embeddings\n        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n        self.decoder_embedding = nn.Embedding(trg_vocab_size, d_model)\n        self.pos_encoder = PositionalEncoding(d_model)\n\n        # Use manual self-attention to avoid nested tensor warning\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=n_heads,\n            dim_feedforward=d_ff,\n            dropout=dropout,\n            batch_first=True\n        )\n        decoder_layer = nn.TransformerDecoderLayer(\n            d_model=d_model,\n            nhead=n_heads,\n            dim_feedforward=d_ff,\n            dropout=dropout,\n            batch_first=True\n        )\n\n        self.encoder = nn.TransformerEncoder(encoder_layer, n_layers)\n        self.decoder = nn.TransformerDecoder(decoder_layer, n_layers)\n\n        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n        self.d_model = d_model\n        self.src_pad_idx = 0  # PAD token\n        self.trg_pad_idx = 0  # PAD token\n\n    def make_src_mask(self, src):\n        # Create source padding mask for attention\n        return (src == self.src_pad_idx)\n\n    def make_trg_mask(self, trg):\n        # Create target padding mask\n        trg_pad_mask = (trg == self.trg_pad_idx)\n\n        # Create triangular causal mask to prevent seeing future tokens\n        trg_len = trg.shape[1]\n        trg_sub_mask = torch.triu(torch.ones((trg_len, trg_len)), diagonal=1).bool().to(device)\n\n        return trg_pad_mask, trg_sub_mask\n\n    def forward(self, src, trg):\n        # Create masks\n        src_mask = self.make_src_mask(src)\n        trg_pad_mask, trg_sub_mask = self.make_trg_mask(trg)\n\n        # Embeddings and positional encoding\n        src_emb = self.pos_encoder(self.encoder_embedding(src) * math.sqrt(self.d_model))\n        trg_emb = self.pos_encoder(self.decoder_embedding(trg) * math.sqrt(self.d_model))\n\n        # Encoder\n        enc_output = self.encoder(src_emb, src_key_padding_mask=src_mask)\n\n        # Decoder (PyTorch's transformer expects different mask format)\n        output = self.decoder(\n            trg_emb,\n            enc_output,\n            tgt_mask=trg_sub_mask,\n            tgt_key_padding_mask=trg_pad_mask,\n            memory_key_padding_mask=src_mask\n        )\n\n        return self.fc_out(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:27:44.254574Z","iopub.execute_input":"2025-05-14T00:27:44.255096Z","iopub.status.idle":"2025-05-14T00:27:44.276896Z","shell.execute_reply.started":"2025-05-14T00:27:44.255080Z","shell.execute_reply":"2025-05-14T00:27:44.276306Z"},"id":"8jGIVHg5kChP"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Initialize model\nsrc_vocab_size = len(src_tokenizer.vocab)\ntrg_vocab_size = len(trg_tokenizer.vocab)\n\nmodel = Transformer(\n    src_vocab_size=src_vocab_size,\n    trg_vocab_size=trg_vocab_size,\n    d_model=256,\n    n_layers=4,\n    n_heads=8,\n    d_ff=512,\n    dropout=0.1\n).to(device)\n\n# Initialize weights\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n\n# Optimizer\noptimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3\n)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:27:44.277686Z","iopub.execute_input":"2025-05-14T00:27:44.277850Z","iopub.status.idle":"2025-05-14T00:27:44.579171Z","shell.execute_reply.started":"2025-05-14T00:27:44.277838Z","shell.execute_reply":"2025-05-14T00:27:44.578551Z"},"id":"sd4TwW5BkChP"},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Training functions\ndef train_epoch(model, dataloader, optimizer, criterion, clip=1.0):\n    model.train()\n    epoch_loss = 0\n\n    for src, trg, _, _ in dataloader:  # Ignore text, only use tensors\n        src, trg = src.to(device), trg.to(device)\n\n        # Forward pass with teacher forcing\n        optimizer.zero_grad()\n        output = model(src, trg[:, :-1])\n\n        # Reshape for loss calculation\n        output_dim = output.shape[-1]\n        output = output.contiguous().view(-1, output_dim)\n        trg = trg[:, 1:].contiguous().view(-1)\n\n        # Calculate loss, backprop and update\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    return epoch_loss / len(dataloader)\n\ndef evaluate_epoch(model, dataloader, criterion):\n    model.eval()\n    epoch_loss = 0\n\n    with torch.no_grad():\n        for src, trg, _, _ in dataloader:  # Ignore text, only use tensors\n            src, trg = src.to(device), trg.to(device)\n\n            # Forward pass\n            output = model(src, trg[:, :-1])\n\n            # Reshape for loss calculation\n            output_dim = output.shape[-1]\n            output = output.contiguous().view(-1, output_dim)\n            trg = trg[:, 1:].contiguous().view(-1)\n\n            # Calculate loss\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n\n    return epoch_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T00:27:44.579883Z","iopub.execute_input":"2025-05-14T00:27:44.580117Z","iopub.status.idle":"2025-05-14T00:27:44.587085Z","shell.execute_reply.started":"2025-05-14T00:27:44.580100Z","shell.execute_reply":"2025-05-14T00:27:44.586239Z"},"id":"fvlCLj5WkChP"},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Training loop\nN_EPOCHS = 20\nbest_valid_loss = float('inf')\npatience = 3\npatience_counter = 0\n\nfor epoch in range(N_EPOCHS):\n    start_time = time.time()\n\n    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n    valid_loss = evaluate_epoch(model, valid_loader, criterion)\n\n    # Learning rate scheduling\n    scheduler.step(valid_loss)\n\n    end_time = time.time()\n    epoch_mins = int((end_time - start_time) / 60)\n    epoch_secs = int((end_time - start_time) % 60)\n\n    # Save best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'best-en-vi-model.pt', _use_new_zipfile_serialization=True)\n        patience_counter = 0\n    else:\n        patience_counter += 1\n\n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.4f} | Train PPL: {math.exp(train_loss):7.4f}')\n    print(f'\\t Val. Loss: {valid_loss:.4f} |  Val. PPL: {math.exp(valid_loss):7.4f}')\n\n    # Early stopping\n    if patience_counter >= patience:\n        print(f'Early stopping after {epoch+1} epochs')\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:15:35.852796Z","iopub.execute_input":"2025-05-14T01:15:35.853145Z","iopub.status.idle":"2025-05-14T02:07:44.272868Z","shell.execute_reply.started":"2025-05-14T01:15:35.853119Z","shell.execute_reply":"2025-05-14T02:07:44.272069Z"},"id":"GH26CTe4kChP","outputId":"cacd3d16-4d15-45f5-e10f-af1f5c6076b9"},"outputs":[{"name":"stdout","text":"Epoch: 01 | Time: 2m 54s\n\tTrain Loss: 3.5016 | Train PPL: 33.1675\n\t Val. Loss: 3.3866 |  Val. PPL: 29.5659\nEpoch: 02 | Time: 3m 20s\n\tTrain Loss: 3.2831 | Train PPL: 26.6588\n\t Val. Loss: 3.2252 |  Val. PPL: 25.1580\nEpoch: 03 | Time: 3m 12s\n\tTrain Loss: 3.1119 | Train PPL: 22.4635\n\t Val. Loss: 3.1056 |  Val. PPL: 22.3227\nEpoch: 04 | Time: 3m 2s\n\tTrain Loss: 2.9635 | Train PPL: 19.3647\n\t Val. Loss: 3.0070 |  Val. PPL: 20.2271\nEpoch: 05 | Time: 3m 25s\n\tTrain Loss: 2.8377 | Train PPL: 17.0765\n\t Val. Loss: 2.9365 |  Val. PPL: 18.8503\nEpoch: 06 | Time: 2m 51s\n\tTrain Loss: 2.7257 | Train PPL: 15.2673\n\t Val. Loss: 2.8775 |  Val. PPL: 17.7691\nEpoch: 07 | Time: 3m 5s\n\tTrain Loss: 2.6261 | Train PPL: 13.8191\n\t Val. Loss: 2.8227 |  Val. PPL: 16.8221\nEpoch: 08 | Time: 2m 44s\n\tTrain Loss: 2.5354 | Train PPL: 12.6212\n\t Val. Loss: 2.7872 |  Val. PPL: 16.2353\nEpoch: 09 | Time: 2m 45s\n\tTrain Loss: 2.4518 | Train PPL: 11.6093\n\t Val. Loss: 2.7567 |  Val. PPL: 15.7477\nEpoch: 10 | Time: 2m 45s\n\tTrain Loss: 2.3725 | Train PPL: 10.7245\n\t Val. Loss: 2.7333 |  Val. PPL: 15.3832\nEpoch: 11 | Time: 2m 45s\n\tTrain Loss: 2.2993 | Train PPL:  9.9671\n\t Val. Loss: 2.7207 |  Val. PPL: 15.1917\nEpoch: 12 | Time: 2m 45s\n\tTrain Loss: 2.2338 | Train PPL:  9.3354\n\t Val. Loss: 2.7018 |  Val. PPL: 14.9068\nEpoch: 13 | Time: 2m 44s\n\tTrain Loss: 2.1685 | Train PPL:  8.7455\n\t Val. Loss: 2.6988 |  Val. PPL: 14.8622\nEpoch: 14 | Time: 2m 43s\n\tTrain Loss: 2.1086 | Train PPL:  8.2367\n\t Val. Loss: 2.6850 |  Val. PPL: 14.6588\nEpoch: 15 | Time: 2m 44s\n\tTrain Loss: 2.0501 | Train PPL:  7.7688\n\t Val. Loss: 2.6848 |  Val. PPL: 14.6558\nEpoch: 16 | Time: 2m 45s\n\tTrain Loss: 1.9961 | Train PPL:  7.3600\n\t Val. Loss: 2.6855 |  Val. PPL: 14.6648\nEpoch: 17 | Time: 2m 45s\n\tTrain Loss: 1.9436 | Train PPL:  6.9841\n\t Val. Loss: 2.6918 |  Val. PPL: 14.7585\nEpoch: 18 | Time: 2m 43s\n\tTrain Loss: 1.8943 | Train PPL:  6.6478\n\t Val. Loss: 2.6955 |  Val. PPL: 14.8127\nEarly stopping after 18 epochs\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Inference function\ndef translate_sentence(model, sentence, src_tokenizer, trg_tokenizer, max_len=70):\n    model.eval()\n\n    # Tokenize and encode source sentence\n    tokens = src_tokenizer.encode(sentence)\n    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n\n    # Initialize with SOS token\n    trg_indexes = [trg_tokenizer.special_tokens[\"<SOS>\"]]\n\n    for i in range(max_len):\n        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n\n        # Get prediction\n        with torch.no_grad():\n            output = model(src_tensor, trg_tensor)\n\n        # Get next token\n        pred_token = output[:, -1, :].argmax(1).item()\n        trg_indexes.append(pred_token)\n\n        # Stop if EOS token\n        if pred_token == trg_tokenizer.special_tokens[\"<EOS>\"]:\n            break\n\n    # Convert tokens to text\n    translated_sentence = trg_tokenizer.decode(trg_indexes)\n\n    return translated_sentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:20:17.878903Z","iopub.execute_input":"2025-05-14T02:20:17.879627Z","iopub.status.idle":"2025-05-14T02:20:17.884758Z","shell.execute_reply.started":"2025-05-14T02:20:17.879597Z","shell.execute_reply":"2025-05-14T02:20:17.884030Z"},"id":"dEIrRPDBkChP"},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Fixed evaluation function\ndef calculate_metrics(model, test_loader, src_tokenizer, trg_tokenizer):\n    model.eval()\n\n    references = []\n    predictions = []\n\n    with torch.no_grad():\n        for src, trg, src_texts, trg_texts in test_loader:\n            src = src.to(device)\n\n            for i in range(min(len(src), 10)):  # Process fewer examples per batch\n                try:\n                    # Get source and reference texts directly\n                    src_text = src_texts[i]\n                    trg_text = trg_texts[i]\n\n                    # Generate translation\n                    pred_text = translate_sentence(model, src_text, src_tokenizer, trg_tokenizer)\n\n                    # Only add if both are non-empty\n                    if pred_text and trg_text:\n                        references.append(trg_text)\n                        predictions.append(pred_text)\n                except Exception as e:\n                    print(f\"Error translating: {e}\")\n\n    # Ensure we have samples to evaluate\n    if not predictions or not references:\n        return {\n            'bleu': 0.0,\n            'rouge1': 0.0,\n            'rouge2': 0.0,\n            'rougeL': 0.0,\n            'num_samples': 0\n        }\n\n    # Calculate BLEU\n    bleu_results = bleu.compute(predictions=predictions, references=[[r] for r in references])\n\n    # Calculate ROUGE\n    rouge_results = rouge.compute(\n        predictions=predictions,\n        references=references\n    )\n\n    return {\n        'bleu': bleu_results['bleu'],\n        'rouge1': rouge_results['rouge1'],\n        'rouge2': rouge_results['rouge2'],\n        'rougeL': rouge_results['rougeL'],\n        'num_samples': len(predictions)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:20:17.885419Z","iopub.execute_input":"2025-05-14T02:20:17.885597Z","iopub.status.idle":"2025-05-14T02:20:17.900427Z","shell.execute_reply.started":"2025-05-14T02:20:17.885582Z","shell.execute_reply":"2025-05-14T02:20:17.899619Z"},"id":"HuZC83_dkChQ"},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Evaluate model\nprint(\"Evaluating model...\")\n# Load best model\nmodel.load_state_dict(torch.load('best-en-vi-model.pt', weights_only=True))\n\nmetrics = calculate_metrics(model, test_loader, src_tokenizer, trg_tokenizer)\n\nprint(f\"Evaluated on {metrics['num_samples']} test samples\")\nprint(f\"BLEU Score: {metrics['bleu']:.4f}\")\nprint(f\"ROUGE-1 Score: {metrics['rouge1']:.4f}\")\nprint(f\"ROUGE-2 Score: {metrics['rouge2']:.4f}\")\nprint(f\"ROUGE-L Score: {metrics['rougeL']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:07:44.306723Z","iopub.execute_input":"2025-05-14T02:07:44.306916Z","iopub.status.idle":"2025-05-14T02:20:17.518204Z","shell.execute_reply.started":"2025-05-14T02:07:44.306902Z","shell.execute_reply":"2025-05-14T02:20:17.517475Z"},"id":"l01_Xry9kChQ","outputId":"4c0af685-5ec7-4d2a-b15b-301584164362"},"outputs":[{"name":"stdout","text":"Evaluating model...\nEvaluated on 5918 test samples\nBLEU Score: 0.0918\nROUGE-1 Score: 0.4403\nROUGE-2 Score: 0.2123\nROUGE-L Score: 0.3911\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Example translations\ntest_english = [\n    \"Hello, how are you?\",\n    \"I would like to learn Vietnamese.\",\n    \"The weather is beautiful today.\",\n    \"Thank you for your help.\",\n    \"Where is the nearest restaurant?\"\n]\n\nfor sentence in test_english:\n    translation = translate_sentence(model, sentence, src_tokenizer, trg_tokenizer)\n    print(f\"English: {sentence}\")\n    print(f\"Vietnamese: {translation}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:20:17.518848Z","iopub.execute_input":"2025-05-14T02:20:17.519083Z","iopub.status.idle":"2025-05-14T02:20:17.877270Z","shell.execute_reply.started":"2025-05-14T02:20:17.519058Z","shell.execute_reply":"2025-05-14T02:20:17.876626Z"},"id":"XR9c7OHTkChQ","outputId":"608b1291-e873-4123-d406-844d844cf213"},"outputs":[{"name":"stdout","text":"English: Hello, how are you?\nVietnamese: chào anh, anh bạn?\n\nEnglish: I would like to learn Vietnamese.\nVietnamese: tôi muốn về việt nam việt nam.\n\nEnglish: The weather is beautiful today.\nVietnamese: chúng ta sẽ rất đẹp.\n\nEnglish: Thank you for your help.\nVietnamese: cảm ơn vì đã giúp.\n\nEnglish: Where is the nearest restaurant?\nVietnamese: nhà hàng đâu?\n\n","output_type":"stream"}],"execution_count":32}]}